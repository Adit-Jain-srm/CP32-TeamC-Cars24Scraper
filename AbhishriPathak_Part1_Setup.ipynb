{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9724483f",
   "metadata": {},
   "source": [
    "Part 1: Setup and Initialization\n",
    "\n",
    "This section focuses on setting up the web scraping environment and initializing the project. It involves:\n",
    "\n",
    "~Importing the necessary libraries required for data extraction and analysis.\n",
    "\n",
    "~Creating the project structure within a Jupyter Notebook (.ipynb) for better organization and reproducibility.\n",
    "\n",
    "~Sending a test HTTP request to the Cars24 website to verify connectivity and ensure that the website can be accessed successfully.\n",
    "\n",
    "This initial step is crucial as it ensures that the team members can proceed seamlessly and establish a strong foundation helping maintain efficiency, consistency, and smooth integration throughout the entire project workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4945296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Install Dependencies (Optional)\n",
    "# Uncomment and run the following lines to install the required libraries if not already installed.\n",
    "# This is useful when setting up the environment in a new kernel.\n",
    "\n",
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install pandas\n",
    "\n",
    "# Note: It's recommended to create a requirements.txt file for better dependency management.\n",
    "# To generate a requirements.txt file, run the following command in the terminal:\n",
    "# pip freeze > requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56963ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Versions:\n",
      "requests: 2.32.3\n",
      "beautifulsoup4(bs4): N/A\n",
      "pandas: 2.2.2\n",
      "Python: 3.12.3 (tags/v3.12.3:f6650f9, Apr  9 2024, 14:05:25) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Importing Required Libraries\n",
    "\n",
    "import requests                      # For sending HTTP requests\n",
    "from bs4 import BeautifulSoup         # For parsing HTML content\n",
    "import pandas as pd    # For data manipulation and analysis\n",
    "import os                  # For creating project structure\n",
    "import sys                \n",
    "from urllib import robotparser      # For handling robots.txt files\n",
    "\n",
    "# Printing package versions for reproducibility\n",
    "\n",
    "print(\"Library Versions:\")\n",
    "print(f\"requests:\", requests.__version__)\n",
    "print(f\"beautifulsoup4(bs4): {BeautifulSoup.__version__ if hasattr(BeautifulSoup, '__version__') else 'N/A'}\")\n",
    "print(f\"pandas:\", pd.__version__)\n",
    "print(f\"Python:\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c7f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully connected and validated Cars24 Mumbai Hyundai page structure.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Sending a test HTTP request to verify connectivity (hardened version)\n",
    "\n",
    "test_url = \"https://www.cars24.com/buy-used-hyundai-cars-mumbai/?sort=bestmatch&serveWarrantyCount=true&listingSource=Homepage_Filters\"\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "})\n",
    "\n",
    "try:\n",
    "    response = session.get(test_url, timeout=10)\n",
    "    response.raise_for_status()  # Raises HTTPError for bad responses\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    # Minimal validation: check if the page <title> contains 'Hyundai' and 'Mumbai'\n",
    "    page_title = soup.title.string if soup.title else \"\"\n",
    "    if \"Hyundai\" in page_title and \"Mumbai\" in page_title:\n",
    "        print(\"Successfully connected and validated Cars24 Mumbai Hyundai page structure.\")\n",
    "    else:\n",
    "        print(\"Connected, but page structure/title did not match expectations. Title found:\", page_title)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"HTTP request failed: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904a65a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not allowed to scrape: https://www.cars24.com/buy-used-hyundai-cars-mumbai/\n"
     ]
    }
   ],
   "source": [
    "# Step 2b: Check robots.txt permissions before scraping\n",
    "# This step demonstrates responsible scraping by checking the site's robots.txt rules.\n",
    "\n",
    "from urllib import robotparser\n",
    "\n",
    "robots_url = \"https://www.cars24.com/robots.txt\"\n",
    "rp = robotparser.RobotFileParser()\n",
    "rp.set_url(robots_url)\n",
    "rp.read()\n",
    "\n",
    "test_url = \"https://www.cars24.com/buy-used-hyundai-cars-mumbai/\"\n",
    "if rp.can_fetch(\"*\", test_url):\n",
    "    print(f\"Allowed to scrape: {test_url}\")\n",
    "else:\n",
    "    print(f\"Not allowed to scrape: {test_url}\")\n",
    "\n",
    "# Note: This check ensures we do not scrape disallowed paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project directory 'cars24_hyundai_mumbai' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Extra Step: Creating project structure\n",
    "\n",
    "project_dir = \"cars24_hyundai_mumbai\"              # name of the project folder\n",
    "if not os.path.exists(project_dir):                # Check if the directory already exists\n",
    "    os.makedirs(project_dir)                       # If not, create the directory\n",
    "    print(f\"Project directory '{project_dir}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Project directory '{project_dir}' already exists.\")                # Printing a message if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Data Cleaning\n",
    "# To be completed by the next team members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ec5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Data Extraction\n",
    "# To be completed by the next team members\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
